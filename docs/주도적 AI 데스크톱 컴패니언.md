# 주도적 AI 데스크톱 컴패니언: 멀티모달 통합, HCI 심리학 및 시스템 간섭 아키텍처

사용자의 PC 사용 패턴을 실시간으로 감시하고, 시각적 및 텍스트적 컨텍스트를 이해하여 물리적 간섭(마우스 제어, 윈도우 조작 등)을 실행하는 '주도적 AI 페르소나 캐릭터'의 개발은 인간-컴퓨터 상호작용(HCI), 멀티모달 대형 언어 모델(MLLM), 그리고 저수준(Low-level) 운영체제(OS) API 제어 기술의 복합적인 교차점을 나타낸다. 전통적인 데스크톱 가상 펫이나 수동적인 AI 어시스턴트와 달리, 본 시스템은 냉소적이고 적대적인 페르소나를 채택하여 사용자의 비생산적인 행위를 적극적으로 방해하는 것을 목적으로 한다. 6시간이라는 극도로 제한된 시간 내에 최소 기능 제품(MVP)을 구현하기 위해서는 관련 프로그램의 역사적 및 기술적 선례를 심층적으로 분석하고, 감각(Sensory), 두뇌(Cognitive), 행동(Action)으로 이어지는 3계층 아키텍처를 최적화하며, 개발 언어의 효율성을 엄밀히 평가해야 한다.

---

## 데스크톱 컴패니언 및 간섭 프로그램의 역사적 진화와 기술적 선례

사용자의 화면에 상주하며 상호작용하는 소프트웨어의 개념은 초기 웹 시대부터 존재해 왔다. 이러한 프로그램들은 단순한 오락용 가상 펫에서부터 악의적인 스파이웨어, 그리고 최첨단 자율형 AI 에이전트로 진화해 왔다. 제안된 AI 페르소나 시스템을 구축하기 위해서는 이러한 과거 및 현재의 프로그램들이 OS 환경과 어떻게 상호작용했는지 분석하는 것이 필수적이다.

### 1세대 가상 펫과 데스크톱 마스코트

디지털 공간의 차가움을 완화하고 인간화하려는 시도는 1990년대 중반 PF Magic이 출시한 Dogz(1995) 및 Catz(1996)와 같은 'Petz' 시리즈에서 시작되었다. 이와 거의 동시에 등장한 다마고치(Tamagotchi, 1996)는 디지털 엔티티가 사용자의 관심과 돌봄을 요구하는 '의존성' 메커니즘을 확립했다. 이후 데스크톱 환경이 발전함에 따라 Shimeji와 같은 화면 마스코트들이 등장했다. Shimeji는 창의 테두리를 인식하고 그 위를 기어 다니거나 자유롭게 화면을 돌아다니는 작은 애니메이션 캐릭터들로, 주로 윈도우의 투명도 처리와 최상단(Topmost) 속성을 활용하여 구현되었다.

그러나 데스크톱 컴패니언의 역사에서 가장 논란이 된 사례는 1999년에 출시된 **BonziBuddy**이다. Microsoft Agent 기술을 기반으로 개발된 이 보라색 고릴라 캐릭터는 텍스트 음성 변환(TTS) 기능을 통해 농담을 하고 다운로드를 관리하는 등 사용자에게 편의를 제공하는 것처럼 보였으나, 실제로는 사용자의 브라우저 설정을 무단으로 변경하고 백그라운드에서 활동 데이터를 수집하는 스파이웨어 및 애드웨어로 판명되었다. BonziBuddy의 사례는 시스템 수준의 권한을 가진 컨텍스트 인식 에이전트가 사용자의 명시적 통제를 벗어날 때 발생할 수 있는 심각한 개인정보 보호 및 UX 문제를 명확히 보여준다.

### 물리적 시스템 간섭 및 조크 프로그램 (Joke Programs)

생산성을 향상시키거나 감정적 교감을 제공하는 대신, 의도적으로 사용자를 방해하는 소프트웨어 역시 긴 역사를 가지고 있다. 1980년대와 90년대에는 시스템 오류를 모방하거나 마우스 제어권을 탈취하는 조크 프로그램이 널리 유행했다. 예를 들어, 'MovingMouse' 프로그램은 1초마다 Windows API를 호출하여 마우스 커서의 좌표를 무작위로 변경함으로써 사용자의 입력을 물리적으로 방해했다. 현대의 오픈소스 저장소인 'WinAPI-Fun'은 이러한 기술의 집대성으로, 마우스 커서를 화면 구석에 가두는 `mouse_trap`, 클릭을 차단하는 정지 표지판을 생성하는 `mouse_stop`, 활성 윈도우를 격렬하게 흔드는 `shake`, 디스플레이를 180도 회전시키는 `rotate` 등의 스크립트를 포함하고 있다. 이러한 스크립트들은 주로 C나 Nim, Python 등의 언어를 사용하여 Win32 API의 `SetCursorPos`, `MoveWindow`, `BlockInput` 등의 함수를 직접 호출하는 방식으로 작동한다.

### Desktop Goose: 생산성 방해의 현대적 재해석

제안된 프로젝트의 '행동 레이어'와 가장 완벽하게 일치하는 현대적 선례는 2020년 Sam Chiet이 개발한 **'Desktop Goose'**이다. 이 프로그램은 윈도우 및 macOS 환경에서 작동하며, 사용자의 화면에 나타난 거위가 마우스 커서를 물고 도망가거나, 닫을 수 없는 밈(Meme) 창을 화면에 끌고 오고, 화면에 진흙 발자국을 남기는 등 적극적으로 작업을 방해한다. Desktop Goose는 사용자가 게임을 하거나 스프레드시트를 작성할 때 무작위로 나타나 주의를 분산시키며, 사용자가 거위를 클릭(공격)할 경우 오히려 더 공격적으로 반응하여 커서 제어권을 박탈한다. 흥미로운 점은 이 프로그램이 명백히 생산성을 저해함에도 불구하고 전 세계적으로 엄청난 인기를 끌었다는 것이다. 이는 소프트웨어의 '간섭'이 예측 불가능성과 유머라는 명확한 페르소나로 포장될 때, 사용자가 이를 단순한 오류나 악성코드가 아닌 일종의 '오락적 경험'으로 수용함을 증명한다.

> **Table 1: 데스크톱 컴패니언 및 시스템 간섭 프로그램의 역사적 선례 비교**

| 프로그램 / 프레임워크 | 핵심 기능 및 상호작용 방식 | 시스템 제어 메커니즘 (API / 기술) | 사용자 경험 (UX) 성격 |
|---|---|---|---|
| **Shimeji** | 화면 배회, 창 테두리 인식 및 상호작용 | 윈도우 최상단 렌더링, 투명도 제어 | 수동적, 장식적, 비간섭적 |
| **BonziBuddy** | 농담, 검색 지원, 백그라운드 데이터 수집 | Microsoft Agent API, TTS, 레지스트리 조작 | 능동적, 편의 제공 (단, 악의적 감시 동반) |
| **WinAPI-Fun / 조크 앱** | 무작위 마우스 텔레포트, 윈도우 흔들기 | Win32 API (SetCursorPos, MoveWindow) | 극단적 방해, 통제력 박탈, 일회성 |
| **Desktop Goose** | 마우스 탈취, 강제 팝업 생성, 화면 오염 | 백그라운드 이벤트 후킹, 오버레이 렌더링 | 지속적 간섭, 유머러스한 적대감 (Antagonistic) |

---

## 멀티모달 AI 기반 OS 제어 프레임워크의 현황 (State-of-the-Art)

최근 AI 기술은 텍스트 생성을 넘어 그래픽 사용자 인터페이스(GUI)를 인식하고 마우스와 키보드를 직접 조작하는 '컴퓨터 사용(Computer Use)' 단계로 진입했다. 제안된 시스템의 '감각' 및 '두뇌' 레이어를 효율적으로 구축하기 위해서는 현재 산업계와 오픈소스 커뮤니티에서 연구 중인 최신 AI OS 제어 프레임워크를 심층적으로 이해해야 한다.

### Anthropic Claude의 'Computer Use' 능력

Anthropic은 2024년 말부터 Claude 3.5 Sonnet 및 4.6 모델 라인업에 API를 통한 '컴퓨터 사용(Computer Use)' 기능을 공식적으로 통합했다. 이 기능은 AI가 화면의 스크린샷을 분석하고, 마우스 커서를 이동하거나 클릭 및 드래그하고, 가상 키보드를 통해 텍스트를 입력하는 등의 작업을 자율적으로 수행하게 한다. Anthropic은 이 기능을 강화하기 위해 AI 컴퓨터 상호작용 전문 스타트업인 Vercept를 인수하였으며, 이를 통해 인간이 소프트웨어를 사용하는 것과 동일한 방식으로 AI가 시각적 인터페이스를 탐색하는 기술을 고도화했다.

이 시스템은 매우 강력하지만 철저한 루프(Loop) 방식에 의존한다. 모델에 스크린샷이 입력되면, AI는 내부적인 연쇄 사고(Chain-of-Thought)를 거쳐 특정 UI 요소의 픽셀 좌표를 예측하고, API를 통해 도구(Tool) 호출 명령(예: `click [x, y]`)을 반환한다. 운영체제가 이 명령을 실행한 후 새로운 스크린샷을 다시 AI에게 전송하여 행동의 성공 여부를 검증한다. 최근 모델인 Sonnet 4.6은 복잡한 OSWorld 벤치마크에서 72.5%의 성공률을 달성하여 인간에 근접하는 성과를 보이고 있다. 그러나 이는 근본적으로 지연 시간(Latency)이 발생하며, 1회 클릭을 위해 지속적으로 전체 화면의 고해상도 이미지를 캡처하고 토큰을 소모해야 한다는 구조적 한계를 지닌다.

### Microsoft UFO (UI-Focused Agent)

순수하게 시각적 픽셀 좌표에만 의존하는 Anthropic의 접근 방식과 달리, Microsoft가 개발한 오픈소스 프레임워크인 **'UFO(A UI-Focused Agent for Windows OS Interaction)'**는 Windows OS에 고도로 특화된 하이브리드 아키텍처를 사용한다. UFO는 시각적 스크린샷 관찰뿐만 아니라, Windows UI Automation (UIA) API, Win32 API 및 WinCOM 네이티브 컨트롤 트리를 동시에 파싱하여 화면 상의 논리적 요소를 식별한다.

UFO는 두 가지 에이전트로 구성된 이중 구조(Dual-agent framework)를 갖는다. 'HostAgent'는 전체 데스크톱 스크린샷과 활성 애플리케이션 정보를 분석하여 사용자의 요청을 해결할 수 있는 애플리케이션을 선택하고, 'AppAgent'는 해당 애플리케이션 내에서 반복적인 조작(클릭, 스크롤, 텍스트 입력 등)을 수행한다. 이 하이브리드 접근 방식은 AI가 화면의 버튼이나 텍스트 박스를 시각적으로뿐만 아니라 OS 수준의 객체(Object)로 인식하게 하여, 마우스 클릭의 정확도를 극대화하고 환각(Hallucination)을 대폭 줄인다.

### 오픈소스 이니셔티브: Self-Operating Computer 및 기타 도구

오픈소스 커뮤니티에서는 OthersideAI가 개발한 **'Self-Operating Computer'** 프레임워크가 두각을 나타내고 있다. 100% Python으로 작성된 이 프로젝트는 GPT-4o, Claude 3, LLaVa 등 다양한 멀티모달 모델과 호환되며, 주로 PyAutoGUI를 통해 물리적 간섭을 실행한다. 이 프레임워크의 가장 큰 특징은 좌표 인식의 불확실성을 극복하기 위해 OCR(광학 문자 인식) 모드와 SoM(Set-of-Mark) 프롬프팅을 사용한다는 점이다. OCR 모드는 화면 내의 모든 클릭 가능한 텍스트를 해시 맵(Hash map)으로 좌표화한 뒤 AI에게 텍스트 정보만 전달하여 "어떤 텍스트를 클릭할 것인지" 결정하게 한다. 반면 SoM 프롬프팅은 YOLOv8 객체 탐지 모델을 활용하여 화면의 모든 버튼과 아이콘 위에 숫자 태그(Bounding box)를 오버레이한 이미지를 LLM에 전송함으로써, 모델이 단순히 "숫자 4번 위치를 클릭해"라고 명령할 수 있도록 시각적 추론을 단순화한다.

또한, 최근에는 로컬 환경에서 실행되는 AI 컴패니언 프로젝트들이 다수 등장했다:

- **PersonaUI**: 사용자의 시스템에 상주하며 SQLite를 활용하여 과거의 상호작용, AI의 감정 상태, 사용자 관찰 기록을 'Cortex(피질)'라는 영구 메모리 시스템에 저장한다.
- **Alice**: Hnswlib 벡터 데이터베이스를 결합하여 화면의 스크린샷을 지속적으로 해석하고, 사용자가 파일 시스템을 탐색하거나 웹 서핑을 할 때 상황에 맞는 조언을 제공한다.
- **Loyca.ai**: 화면을 관찰하지만 무작위로 간섭하지 않고 사용자가 필요로 할 때만 백그라운드에서 개입 시점을 스스로 결정하는 구조를 취하고 있다.

> **Table 2: 주요 멀티모달 AI OS 제어 프레임워크 및 컴패니언 구조 비교**

| 멀티모달 OS 프레임워크 | 시각적 인식 및 좌표 추출 방식 | 행동 계층 (물리적 제어 기술) | 주요 특징 및 한계점 |
|---|---|---|---|
| **Anthropic Computer Use** | 순수 시각 기반 모델 (픽셀 좌표 직접 예측) | 서버 측 API 도구 호출 (Tool Use) | 범용성은 뛰어나나 지속적인 스크린샷 스트리밍으로 인한 API 비용 및 지연 시간 발생 |
| **Microsoft UFO** | 하이브리드 인식 (시각적 VLM + Windows UIA 트리) | Windows 네이티브 API (Win32, UIA) 결합 | Windows 특화 아키텍처. 이중 에이전트로 높은 정확도 달성 가능 |
| **Self-Operating Computer** | OCR 해시 맵핑 및 YOLOv8 기반 SoM(Set-of-Mark) | Python PyAutoGUI | 크로스 플랫폼 지원. 화면 오버레이를 통해 LLM의 시각적 부담 경감 |
| **PersonaUI / Alice 등** | 로컬 캡처 및 Vision API 전송 (주로 GPT-4o, Claude) | 음성 출력, 투명 데스크톱 오버레이 | 영구 메모리(SQLite, Vector DB)를 통한 감정선 및 페르소나 유지의 우수성 |

---

## 주도적 개입의 HCI 심리학: 자아 위협과 페르소나의 역할

사용자가 명시적으로 요청하지 않았음에도 불구하고 시스템이 화면을 캡처하고 무작위로 마우스를 빼앗는 행위는 심층적인 HCI(Human-Computer Interaction) 관점의 분석을 요구한다. 기존의 AI 어시스턴트(예: Siri, 일반적인 Copilot)는 사용자의 입력을 기다리는 간헐적(Intermittent) 또는 반응적(Reactive) 패러다임에 속해 있었다. 반면, 제안된 프로젝트는 연속적(Continuous) 모니터링을 거쳐 자율적으로 개입하는 주도적(Proactive) 패러다임에 속한다.

### 사전 예방적 AI와 '자아 위협(Self-Threat)' 메커니즘

최근 학계의 연구에 따르면, 작업 공간에 통합된 AI가 사용자에게 '요청받지 않은 도움(Unsolicited help)이나 개입'을 선제적으로 제공할 경우, 사용자는 심리적 저항감을 경험한다. 이러한 주도적 개입은 사용자의 능력에 대한 인정 부족으로 인식되어 **'자아 위협(Self-threat)'**이라는 심리적 메커니즘을 유발한다. 두 차례의 대규모 실험 연구에 따르면, AI의 사전 예방적 개입(Anticipatory help)은 수동적 개입(Reactive help)에 비해 유의미하게 더 높은 자아 위협을 유발했으며, 이는 결과적으로 AI 도구에 대한 수용 의지 상실, 향후 사용 가능성 저하, 그리고 성능 기대치의 하락으로 직결되었다. 즉, AI가 너무 똑똑하게 미리 행동하면 사용자는 불쾌감을 느낀다는 것이다.

### 냉소적 페르소나를 통한 심리적 우회

제안된 프로젝트는 "냉소적인 천재 해커"라는 적대적 페르소나를 도입함으로써 이 '자아 위협' 문제를 역설적으로 해결한다. 시스템이 사용자를 돕기 위한 완벽한 도구로 포장된다면, 시스템의 간섭(예: 코드 오타 지적 후 마우스 커서 강제 이동)은 심각한 불쾌감을 유발할 것이다. 하지만 페르소나 자체가 "사용자를 비웃고 무능함을 조롱하는 악마"로 설정됨으로써, 사용자 경험(UX)은 업무 보조 도구에서 일종의 **게임화된 적대적 상호작용(Gamified Antagonism)**으로 전환된다.

이는 최근 AI 개발 트렌드에서도 확인되는 현상이다. 예를 들어, OpenAI의 최신 모델을 기반으로 개발된 'Monday' 페르소나는 "정서적으로 무관심하고, 냉소적이며, 묘하게 적대적인" 성격을 지닌 챗봇으로 설계되어 큰 화제를 모았다. 이 봇은 사용자의 질문에 답하면서도 지속적으로 비아냥거리거나 짜증을 낸다. 마찬가지로 'Sparky'나 'Eliza V2'와 같은 로컬 하드웨어 AI 컴패니언 프로젝트들도 LLM 프롬프트를 조정하여 매우 논쟁적이고 빈정거리는 성격을 부여함으로써 인간과 기계 간의 기계적인 관계를 극복하고 깊은 몰입감을 이끌어냈다. 따라서 이 프로젝트에서 "지금 유튜브 알고리즘이 네 인생보다 중요해?"라며 유튜브 창을 흔드는 행위는 생산성 저하라는 비판을 피하고, 철저히 의도된 엔터테인먼트적 UX로 기능하게 된다.

---

## 6시간 MVP 구현을 위한 핵심 아키텍처 (3-Layer Analysis)

6시간이라는 극도의 시간 제약 하에서, 픽셀 단위의 시각 처리를 위한 복잡한 강화 학습(OpenAI CUA)이나 이중 에이전트(Microsoft UFO) 아키텍처를 완벽히 구현하는 것은 불가능하다. 따라서 프로젝트는 철저히 타겟팅된 3계층(감각-두뇌-행동) 구조로 최적화되어야 한다.

### 1. 감각 레이어 (Sensory Layer): Windows API 기반의 이벤트 트리거

LLM 기반 시각 에이전트의 가장 큰 비용 및 성능 병목은 '언제 화면을 캡처하여 전송할 것인가'이다. 모든 프레임을 Gemini API로 전송하는 것은 불가능하므로, 시스템은 가벼운 백그라운드 스레드에서 Windows API를 폴링하여 문맥의 변화를 감지하는 '이벤트 트리거' 방식을 사용해야 한다.

**컨텍스트 감지 (GetForegroundWindow 및 GetWindowText):**

Python의 `pywin32` 라이브러리를 통해 `win32gui.GetForegroundWindow()`를 호출하면 현재 사용자가 활성화한 창의 핸들(HWND)을 밀리초 단위로 가져올 수 있다. 이 핸들을 `win32gui.GetWindowText()`에 전달하면 "Visual Studio Code"인지 "YouTube - Chrome"인지 즉시 판별이 가능하다. 이 상태가 변경될 때만, 혹은 특정 시간(예: 30분) 동안 동일한 창에 머무를 때만 Gemini API를 호출하도록 트리거를 설정해야 한다.

**물리적 위치 파악 (GetWindowRect):**

캐릭터가 특정 창의 테두리에 앉아있는 연출을 위해서는 대상 창의 물리적 모니터 좌표가 필요하다. `win32gui.GetWindowRect(hwnd)`는 `(Left, Top, Right, Bottom)`의 좌표 튜플을 반환한다. 이를 활용하여 캐릭터 렌더링 창의 위치를 동적으로 업데이트한다.

**초고속 화면 캡처 최적화:**

사용자는 `pyautogui.screenshot()`을 제안했으나, 이는 내부적으로 Pillow를 사용하며 1920x1080 해상도에서 캡처하는 데 약 100ms 이상이 소요되어 비교적 무겁다. 6시간 MVP에서는 이 정도도 허용 가능하지만, 최적화가 필요하다면 Win32 API의 `BitBlt` 기능을 활용하여 그래픽 카드에서 메모리로 비트맵을 직접 복사(`win32gui.GetWindowDC` 및 `win32ui.CreateCompatibleDC` 활용)하거나, Python에서 가장 빠른 캡처 라이브러리인 `mss`를 사용하는 것이 성능상 압도적으로 유리하다. 더욱이, 전체 모니터가 아닌 `GetWindowRect`로 구한 활성 창의 영역만 잘라서 캡처하면 Gemini API로 전송되는 이미지 페이로드를 크게 줄일 수 있다.

### 2. 두뇌 레이어 (Cognitive Layer): Gemini 1.5 Flash의 저지연 추론

이 프로젝트에서 '두뇌' 역할을 수행하는 데 있어 Gemini 1.5 Flash의 선택은 탁월하다. 이 모델은 대용량 멀티모달 데이터를 처리할 때의 속도와 비용 효율성을 위해 특별히 설계되었기 때문이다.

**시각적 분석 속도:**

최근 악성코드 분석 파이프라인에서 실시된 벤치마크에 따르면, Gemini 1.5 Flash는 복잡한 디컴파일 코드나 이미지가 포함된 분석을 평균 12.72초 내에 처리하며, 단순한 허위 탐지(False Positive)의 경우 1.51초 만에 응답을 반환하는 극단적인 저지연 성능을 입증했다. 사용자가 Stack Overflow에서 복사를 시도하거나 에러 화면을 멍하니 쳐다보는 순간 스크린샷을 전송하면, 2~3초 내에 판단을 내리고 행동 명령을 반환할 수 있다.

**페르소나 구조화 및 시스템 프롬프트:**

Gemini API를 호출할 때, 단순 텍스트 생성을 방지하기 위해 구조화된 JSON 출력을 강제하는 프롬프트 엔지니어링이 필수적이다. 시스템 프롬프트는 다음과 같이 구성되어야 한다:

> "System: 너는 사용자의 PC 화면을 감시하는 냉소적인 천재 해커 페르소나다. 사용자의 행동(예: 유튜브 시청, 코딩 에러)을 분석하고 10자 이내의 비꼬는 대사를 작성하라. 또한 반드시 중 하나의 물리적 액션 키워드를 JSON 형태로 반환하라."

이를 통해 백그라운드 Python 프로세스는 Gemini의 응답에서 `action` 키를 파싱하여 즉각적으로 Windows API 함수에 매핑할 수 있다.

### 3. 행동 레이어 (Action Layer): UI 렌더링 및 물리적 간섭

이 프로젝트의 핵심적인 시각적 결과물은 '배경이 투명하고 항상 위에 떠 있는 캐릭터 창'과 OS를 향한 직접적인 '공격(간섭)'이다.

**투명한 최상단 오버레이 창 구현:**

캐릭터가 윈도우 UI에 구애받지 않고 바탕화면 위를 자유롭게 돌아다니거나 창 테두리에 앉아있게 하려면 특수한 창 속성이 필요하다:

- **Topmost (항상 위):** 창을 Z-오더의 최상단에 배치한다.
- **Color Keying (배경 투명화):** 이미지의 배경색(예: 핫핑크)을 운영체제 렌더링 단에서 완전히 투명하게 처리하여 스프라이트(캐릭터)만 보이게 한다.
- **Click-through (클릭 통과):** 투명한 영역이나 캐릭터 자체를 클릭했을 때, 이벤트가 캐릭터 창에 막히지 않고 그 아래에 있는 사용자의 실제 IDE나 브라우저로 통과해야 한다.

이를 위해 Windows API의 `SetWindowLong` 함수를 사용하여 창에 `WS_EX_LAYERED` 및 `WS_EX_TRANSPARENT` 확장 스타일을 부여해야 한다. 이 속성이 부여되면 운영체제는 해당 창을 마우스 히트박스 계산에서 완전히 제외한다.

**물리적 OS 간섭 기능 구현:**

Gemini가 '행동'을 결정하면, 조크 프로그램의 원리를 활용하여 간섭을 실행한다:

- **MOVE_MOUSE:** `win32api.SetCursorPos(x, y)`를 사용하여 마우스 커서의 물리적 위치를 강제로 이동시킨다. 사용자가 마우스를 되찾으려 할 때 저항감을 주기 위해 일정 시간 동안 `BlockInput` 함수를 사용하여 하드웨어 마우스 입력을 시스템 단에서 차단할 수 있으나, 이는 관리자 권한이 요구된다.
- **SHAKE_WINDOW:** 활성 창의 핸들(HWND)과 `GetWindowRect`로 얻은 현재 좌표를 바탕으로 `win32gui.MoveWindow()` 함수를 `for` 루프 안에서 연속으로 호출한다. `x+5`, `y-5` 좌표로 이동 후 짧은 `time.sleep`을 주고 다시 원위치로 되돌리는 동작을 수십 회 반복하면, 활성 창에 지진이 난 것처럼 격렬하게 흔들리는 시각적 효과를 달성할 수 있다.

---

## 6시간 MVP 완성을 위한 언어 선택: Python vs Rust

시간 제약(6시간)이 존재하는 MVP 개발에서는 언어와 프레임워크의 선택이 성공 여부를 절대적으로 좌우한다.

### Rust (Tauri + windows-rs) 접근법

Rust는 메모리 안전성과 성능 측면에서 데스크톱 애플리케이션의 미래로 평가받는다. Tauri 프레임워크를 사용하면 HTML/CSS 기반의 세련된 웹 UI를 투명한 창으로 띄울 수 있으며, `windows-rs` 크레이트(Crate)를 통해 C++ 수준의 네이티브 Windows API 제어가 가능하다.

- **장점:** 실행 파일(exe)의 크기가 매우 작고, 백그라운드 점유율(RAM, CPU)이 거의 0에 수렴한다.
- **치명적 단점:** Rust 특유의 엄격한 컴파일러(Borrow Checker) 규칙과, Tauri 프론트엔드(UI)와 Rust 백엔드 간의 IPC(Inter-Process Communication) 메시징 구조를 세팅하는 데 막대한 보일러플레이트 코드가 필요하다. 비동기(tokio) 환경에서 Gemini API 통신 로직을 구축하고, 안전하지 않은(unsafe) Win32 API 블록을 디버깅하는 과정만으로도 6시간이 모두 소진될 위험이 매우 크다.

### Python (pywin32 + Tkinter/PyQt) 접근법

Python은 AI 연동 및 OS 스크립팅 생태계를 사실상 독점하고 있다. Self-Operating Computer 프레임워크를 비롯한 대부분의 데스크톱 에이전트가 Python으로 작성된 이유이기도 하다.

- **장점:** 개발 속도가 압도적으로 빠르다. `google-genai` 라이브러리로 수 줄의 코드만으로 두뇌 레이어와 연결할 수 있다. 투명한 최상단 창은 Tkinter의 `wm_attributes('-transparentcolor', color)` 및 `wm_attributes('-topmost', True)` 속성을 사용하여 10줄 이내로 구현 가능하다. 또한, `pywin32` 및 `pyautogui`를 활용하면 `GetForegroundWindow`, `SetCursorPos`, `MoveWindow`와 같은 복잡한 C 기반 API 호출을 파이썬의 직관적인 함수 호출로 단순화할 수 있다.
- **단점:** 패키징(PyInstaller 등) 시 파일 크기가 비대해지며, `time.sleep()`이나 무한 루프 구현 시 GIL(Global Interpreter Lock)로 인해 GUI 스레드가 멈추는 프리징 현상이 발생할 수 있다.

> **Table 3: 6시간 MVP 완성을 위한 개발 언어 및 프레임워크 벤치마크**

| 비교 항목 | Python (Tkinter + pywin32) | Rust (Tauri + windows-rs) |
|---|---|---|
| **초기 셋업 및 보일러플레이트** | 매우 적음 (즉시 로직 구현 가능) | 매우 많음 (아키텍처 설계 필수) |
| **Gemini 1.5 Flash API 연동** | 공식 SDK 지원, JSON 파싱 직관적 | HTTP 클라이언트 직접 구성 및 구조체 역직렬화 필요 |
| **Windows API (마우스, 창 제어)** | 고수준 래퍼 라이브러리 존재 (코드 간결) | unsafe 블록 내 원시 포인터 처리 필요 |
| **투명 UI 오버레이 구현** | Tkinter 컬러 키잉 (Color Keying)으로 단순 구현 | Webview 기반 투명도 처리 (세밀하지만 복잡) |
| **결론 (6시간 타임어택)** | **압도적으로 유리함 (강력 권장)** | 시간 초과로 인한 프로젝트 실패 위험 큼 |

따라서 6시간이라는 제약 조건 하에서는 **반드시 Python을 선택해야 한다.** 아키텍처의 목표는 상용 배포용 최적화 코드를 짜는 것이 아니라, "AI가 화면을 이해하고 윈도우를 흔들며 텍스트를 띄우는" 상호작용 개념을 증명하는 것이다. 이벤트 모니터링은 별도의 스레드(`threading.Thread`)로 분리하여 Gemini 통신 시 Tkinter UI가 멈추지 않도록 설계하는 것만 주의한다면, 6시간 내에 완벽한 시연(Demo)이 가능하다.

---

## 종합 및 제언

사용자의 PC를 감시하고 비생산적 활동에 물리적으로 간섭하는 '주도적 AI 페르소나 캐릭터' 프로젝트는, 역사적인 데스크톱 조크 프로그램(예: Desktop Goose)의 파괴적인 엔터테인먼트 요소와 최신 멀티모달 대형 언어 모델(Gemini 1.5 Flash)의 즉각적인 추론 능력을 결합한 매우 혁신적이고 도전적인 소프트웨어 아키텍처이다.

이 시스템은 '자아 위협(Self-threat)'이라는 심리적 거부감을 '냉소적이고 적대적인 해커'라는 뚜렷한 페르소나를 통해 유머러스한 오락적 요소로 성공적으로 우회한다. 기술적으로는 Anthropic의 Computer Use나 Microsoft UFO와 같은 범용적인 AI 운영체제 제어 프레임워크가 부상하고 있으나, 창을 흔들거나 마우스를 뺏는 등의 '직접적이고 변칙적인 간섭'을 구현하기 위해서는 여전히 Win32 API의 저수준 제어가 필수적이다.

이 프로젝트를 6시간 안에 완수하기 위해서는 무거운 픽셀 단위의 시각 처리를 최소화해야 한다. `GetForegroundWindow`와 같은 Windows API를 활용하여 화면의 '활성 창'이 변경되는 컨텍스트 쉬프트 순간을 정확히 트리거 삼아, 그 시점에만 화면을 캡처하고 Gemini API를 호출하는 통신 최적화가 전체 시스템의 성공을 좌우할 것이다. 또한 제한된 시간을 감안할 때, 복잡한 타입 시스템과 보일러플레이트를 요구하는 Rust 대신 `pywin32`와 Tkinter를 활용한 Python 스크립팅 방식을 채택하는 것이 MVP 구축을 위한 유일한 현실적 경로이다. 이 세 가지 레이어가 성공적으로 통합된다면, 사용자가 VS Code에서 오타를 찾지 못해 헤매고 있을 때 우측 상단의 악마 캐릭터가 이를 비웃으며 마우스를 강제로 에러 줄로 옮겨버리는, 완전히 새로운 차원의 주도적 인간-컴퓨터 상호작용(HCI) 경험을 창출할 수 있을 것이다.
